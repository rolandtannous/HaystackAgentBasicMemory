{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:12.370522Z",
     "start_time": "2023-04-16T22:33:12.363673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Activate logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:16.212954Z",
     "start_time": "2023-04-16T22:33:12.368075Z"
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    " openai_api_key = getpass(\"Enter OpenAI API key:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:27.913886Z",
     "start_time": "2023-04-16T22:33:21.409182Z"
    }
   },
   "outputs": [],
   "source": [
    "from haystack.document_stores import InMemoryDocumentStore, ElasticsearchDocumentStore\n",
    "\n",
    "# document_store = InMemoryDocumentStore(\n",
    "#     similarity=\"cosine\",\n",
    "#     index=\"document\",\n",
    "#     embedding_field=\"embedding\",\n",
    "#     embedding_dim=1536\n",
    "# )\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"testapril17\",\n",
    "    embedding_field=\"embedding\",\n",
    "    embedding_dim=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T18:17:28.383112Z",
     "start_time": "2023-04-06T18:17:27.131964Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# # load seven wonders dataset from datasets and write documents into document store\n",
    "\n",
    "# dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "# document_store.write_documents(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:36.166173Z",
     "start_time": "2023-04-16T22:33:35.970688Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU - Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "# define retriever model , update dense vector embeddings on document store index and define generator model\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"text-embedding-ada-002\",\n",
    "    api_key=openai_api_key,\n",
    "    max_seq_len=1024,\n",
    "    top_k=4,\n",
    ")\n",
    "# document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:42.899563Z",
     "start_time": "2023-04-16T22:33:42.896612Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the QA tool's prompt template\n",
    "\n",
    "from haystack.nodes import PromptNode, PromptTemplate\n",
    "\n",
    "QA_promptnode = PromptTemplate(\n",
    "            name=\"zero-shot-QA\", \n",
    "            prompt_text=\"You are a helpful and knowledgeable agent. Only Answer if the {documents} contain the answer. If the user question is not related to the provided {documents}, say I don't have an answer\\n\"\n",
    "            \"Question: {query}\\n\"\n",
    "            \"Answer:\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:47.749148Z",
     "start_time": "2023-04-16T22:33:46.931729Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare the QA pipeline's prompt node\n",
    "QA_builder = PromptNode(model_name_or_path=\"text-davinci-003\", api_key=openai_api_key, default_prompt_template=QA_promptnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:33:49.613002Z",
     "start_time": "2023-04-16T22:33:49.609080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the QA pipeline tool\n",
    "from haystack import Pipeline\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=QA_builder, name=\"Generator\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:04.213792Z",
     "start_time": "2023-04-16T22:41:03.759133Z"
    }
   },
   "outputs": [],
   "source": [
    "from haystack_memory.prompt_templates import memory_template\n",
    "from haystack.agents import Agent, Tool\n",
    "from haystack.nodes import PromptNode\n",
    "\n",
    "# create agent prompt node and define our Agent \"memory_agent\"\n",
    "prompt_node = PromptNode(model_name_or_path=\"text-davinci-003\", api_key=openai_api_key, max_length=512,\n",
    "                         stop_words=[\"Observation:\"])\n",
    "memory_agent = Agent(prompt_node=prompt_node, prompt_template=memory_template)\n",
    "# Define the first tool: A document store QA tool based on the pipeline\n",
    "search_tool = Tool(name=\"DocumentStore_QA\",\n",
    "                   pipeline_or_node=pipe,\n",
    "                   description=\"Access this tool to find missing information needed to answer questions.\",\n",
    "                   output_variable=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:04.571905Z",
     "start_time": "2023-04-16T22:41:04.564809Z"
    }
   },
   "outputs": [],
   "source": [
    "from haystack_memory.memory import MemoryRecallNode\n",
    "\n",
    "working_memory = []\n",
    "sensory_memory = []\n",
    "memory_node = MemoryRecallNode(memory=working_memory)\n",
    "memory_tool = Tool(name=\"Memory\",\n",
    "                   pipeline_or_node=memory_node,\n",
    "                   description=\"Your memory. Always access this tool first to remember what you have learned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:06.503336Z",
     "start_time": "2023-04-16T22:41:06.499060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the memory and the search tool to the agent\n",
    "memory_agent.add_tool(search_tool)\n",
    "memory_agent.add_tool(memory_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:19.037155Z",
     "start_time": "2023-04-16T22:41:08.669081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent memory-shot-react started with {'query': \"where did zeus' golden sandals rest?\", 'params': None}\n",
      "\u001B[32m access\u001B[0m\u001B[32m my\u001B[0m\u001B[32m memory\u001B[0m\u001B[32m to\u001B[0m\u001B[32m see\u001B[0m\u001B[32m if\u001B[0m\u001B[32m I\u001B[0m\u001B[32m have\u001B[0m\u001B[32m any\u001B[0m\u001B[32m information\u001B[0m\u001B[32m about\u001B[0m\u001B[32m Zeus\u001B[0m\u001B[32m'\u001B[0m\u001B[32m golden\u001B[0m\u001B[32m sand\u001B[0m\u001B[32mals\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Memory\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m Input\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Where\u001B[0m\u001B[32m did\u001B[0m\u001B[32m Zeus\u001B[0m\u001B[32m'\u001B[0m\u001B[32m golden\u001B[0m\u001B[32m sand\u001B[0m\u001B[32mals\u001B[0m\u001B[32m rest\u001B[0m\u001B[32m?\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\u001B[0mObservation: \u001B[33m[]\u001B[0m\n",
      "Thought: \u001B[32m I\u001B[0m\u001B[32m don\u001B[0m\u001B[32m't\u001B[0m\u001B[32m have\u001B[0m\u001B[32m any\u001B[0m\u001B[32m information\u001B[0m\u001B[32m about\u001B[0m\u001B[32m Zeus\u001B[0m\u001B[32m'\u001B[0m\u001B[32m golden\u001B[0m\u001B[32m sand\u001B[0m\u001B[32mals\u001B[0m\u001B[32m in\u001B[0m\u001B[32m my\u001B[0m\u001B[32m memory\u001B[0m\u001B[32m,\u001B[0m\u001B[32m so\u001B[0m\u001B[32m I\u001B[0m\u001B[32m need\u001B[0m\u001B[32m to\u001B[0m\u001B[32m use\u001B[0m\u001B[32m another\u001B[0m\u001B[32m tool\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Document\u001B[0m\u001B[32mStore\u001B[0m\u001B[32m_\u001B[0m\u001B[32mQ\u001B[0m\u001B[32mA\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m Input\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Where\u001B[0m\u001B[32m did\u001B[0m\u001B[32m Zeus\u001B[0m\u001B[32m'\u001B[0m\u001B[32m golden\u001B[0m\u001B[32m sand\u001B[0m\u001B[32mals\u001B[0m\u001B[32m rest\u001B[0m\u001B[32m?\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\u001B[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001B[33mZeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\u001B[0m\n",
      "Thought: \u001B[32m Ok\u001B[0m\u001B[32m,\u001B[0m\u001B[32m the\u001B[0m\u001B[32m observation\u001B[0m\u001B[32m provided\u001B[0m\u001B[32m me\u001B[0m\u001B[32m with\u001B[0m\u001B[32m the\u001B[0m\u001B[32m answer\u001B[0m\u001B[32m,\u001B[0m\u001B[32m so\u001B[0m\u001B[32m I\u001B[0m\u001B[32m can\u001B[0m\u001B[32m now\u001B[0m\u001B[32m provide\u001B[0m\u001B[32m the\u001B[0m\u001B[32m final\u001B[0m\u001B[32m answer\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mFinal\u001B[0m\u001B[32m Answer\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Zeus\u001B[0m\u001B[32m'\u001B[0m\u001B[32m golden\u001B[0m\u001B[32m sand\u001B[0m\u001B[32mals\u001B[0m\u001B[32m rested\u001B[0m\u001B[32m upon\u001B[0m\u001B[32m a\u001B[0m\u001B[32m foot\u001B[0m\u001B[32mst\u001B[0m\u001B[32mool\u001B[0m\u001B[32m decorated\u001B[0m\u001B[32m with\u001B[0m\u001B[32m an\u001B[0m\u001B[32m Amazon\u001B[0m\u001B[32momach\u001B[0m\u001B[32my\u001B[0m\u001B[32m in\u001B[0m\u001B[32m relief\u001B[0m\u001B[32m.\u001B[0m\u001B[32m The\u001B[0m\u001B[32m passage\u001B[0m\u001B[32m underneath\u001B[0m\u001B[32m the\u001B[0m\u001B[32m throne\u001B[0m\u001B[32m was\u001B[0m\u001B[32m restricted\u001B[0m\u001B[32m by\u001B[0m\u001B[32m painted\u001B[0m\u001B[32m screens\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\u001B[0m"
     ]
    }
   ],
   "source": [
    "from haystack_memory.utils import MemoryUtils\n",
    "\n",
    "# Chat with the agent\n",
    "memory_utils = MemoryUtils(working_memory=working_memory, sensory_memory=sensory_memory, agent=memory_agent)\n",
    "result = memory_utils.chat(\"where did zeus' golden sandals rest?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:28.797265Z",
     "start_time": "2023-04-16T22:41:28.794066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"where did zeus' golden sandals rest?\", \"Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\"]\n"
     ]
    }
   ],
   "source": [
    "print(working_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:29.687621Z",
     "start_time": "2023-04-16T22:41:29.681238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"where did zeus' golden sandals rest?\", 'answers': [<Answer {'answer': \"Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\", 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}>], 'transcript': \"You are a helpful agent. To achieve your goal of answering questions correctly, use step by step thinking and\\nuse the following tools to look for answers: DocumentStore_QA: Access this tool to find missing information needed to answer questions.\\nMemory: Your memory. Always access this tool first to remember what you have learned.. Give the tool the full question as input; the tools will respond with observations.\\nRefrain from using prior internal knowledge or tools you don't have access to. You should avoid searching elsewhere and avoid using external sources.\\nOnly use observations returned by the tools you have been given access to.\\nUse the following format:\\n\\nQuestion: the question to be answered\\nThought: Break down the problem into smaller steps. Only use the tools you have been given access to.\\nTool: use one of the following tools to look for answers: DocumentStore_QA: Access this tool to find missing information needed to answer questions.\\nMemory: Your memory. Always access this tool first to remember what you have learned.. Always access the memory tool first.\\nTool Input: the full updated question to be answered\\nObservation: the tool will respond with an observation. If the observation is empty pick another tool to get more information.\\nFinal Answer: Your answer to the question. If the observations provided do not contain the answer or the tools you have access to respond with I don't have an answer, then respond with 'I don't have enough information to answer the question'\\nQuestion: where did zeus' golden sandals rest?\\nThought: Let's work this out it a step by step. I first need to  access my memory to see if I have any information about Zeus' golden sandals.\\nTool: Memory\\nTool Input: Where did Zeus' golden sandals rest?\\n\\nObservation: []\\nThought: I don't have any information about Zeus' golden sandals in my memory, so I need to use another tool.\\nTool: DocumentStore_QA\\nTool Input: Where did Zeus' golden sandals rest?\\n\\n\\nObservation: Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\\nThought: Ok, the observation provided me with the answer, so I can now provide the final answer.\\nFinal Answer: Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\"}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T22:41:44.005150Z",
     "start_time": "2023-04-16T22:41:34.179612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent memory-shot-react started with {'query': 'which muslim general raided the city of Rhodes?', 'params': None}\n",
      "\u001B[32m access\u001B[0m\u001B[32m my\u001B[0m\u001B[32m memory\u001B[0m\u001B[32m to\u001B[0m\u001B[32m recall\u001B[0m\u001B[32m any\u001B[0m\u001B[32m information\u001B[0m\u001B[32m I\u001B[0m\u001B[32m have\u001B[0m\u001B[32m on\u001B[0m\u001B[32m Muslim\u001B[0m\u001B[32m generals\u001B[0m\u001B[32m and\u001B[0m\u001B[32m their\u001B[0m\u001B[32m conqu\u001B[0m\u001B[32mests\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Memory\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m Input\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Muslim\u001B[0m\u001B[32m generals\u001B[0m\u001B[32m and\u001B[0m\u001B[32m their\u001B[0m\u001B[32m conqu\u001B[0m\u001B[32mests\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\u001B[0mObservation: \u001B[33m[\"where did zeus' golden sandals rest?\", \"Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\"]\u001B[0m\n",
      "Thought: \u001B[32m The\u001B[0m\u001B[32m observation\u001B[0m\u001B[32m is\u001B[0m\u001B[32m not\u001B[0m\u001B[32m related\u001B[0m\u001B[32m to\u001B[0m\u001B[32m the\u001B[0m\u001B[32m question\u001B[0m\u001B[32m,\u001B[0m\u001B[32m so\u001B[0m\u001B[32m I\u001B[0m\u001B[32m need\u001B[0m\u001B[32m to\u001B[0m\u001B[32m pick\u001B[0m\u001B[32m another\u001B[0m\u001B[32m tool\u001B[0m\u001B[32m.\u001B[0m\u001B[32m \u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Document\u001B[0m\u001B[32mStore\u001B[0m\u001B[32m_\u001B[0m\u001B[32mQ\u001B[0m\u001B[32mA\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mTool\u001B[0m\u001B[32m Input\u001B[0m\u001B[32m:\u001B[0m\u001B[32m which\u001B[0m\u001B[32m mus\u001B[0m\u001B[32mlim\u001B[0m\u001B[32m general\u001B[0m\u001B[32m raided\u001B[0m\u001B[32m the\u001B[0m\u001B[32m city\u001B[0m\u001B[32m of\u001B[0m\u001B[32m Rhodes\u001B[0m\u001B[32m?\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32m\u001B[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001B[33mMuawiyah I\u001B[0m\n",
      "Thought: \u001B[32m The\u001B[0m\u001B[32m observation\u001B[0m\u001B[32m provides\u001B[0m\u001B[32m the\u001B[0m\u001B[32m answer\u001B[0m\u001B[32m to\u001B[0m\u001B[32m the\u001B[0m\u001B[32m question\u001B[0m\u001B[32m,\u001B[0m\u001B[32m so\u001B[0m\u001B[32m I\u001B[0m\u001B[32m can\u001B[0m\u001B[32m formulate\u001B[0m\u001B[32m my\u001B[0m\u001B[32m final\u001B[0m\u001B[32m answer\u001B[0m\u001B[32m.\u001B[0m\u001B[32m \u001B[0m\u001B[32m\n",
      "\u001B[0m\u001B[32mFinal\u001B[0m\u001B[32m Answer\u001B[0m\u001B[32m:\u001B[0m\u001B[32m Mu\u001B[0m\u001B[32maw\u001B[0m\u001B[32miyah\u001B[0m\u001B[32m I\u001B[0m\u001B[32m raided\u001B[0m\u001B[32m the\u001B[0m\u001B[32m city\u001B[0m\u001B[32m of\u001B[0m\u001B[32m Rhodes\u001B[0m\u001B[32m.\u001B[0m\u001B[32m\u001B[0m"
     ]
    }
   ],
   "source": [
    "result = memory_utils.chat(\"which muslim general raided the city of Rhodes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"where did zeus' golden sandals rest?\", \"Zeus' golden sandals rested upon a footstool decorated with an Amazonomachy in relief. The passage underneath the throne was restricted by painted screens.\", 'which muslim general raided the city of Rhodes?', 'Muawiyah I raided the city of Rhodes.']\n"
     ]
    }
   ],
   "source": [
    "print(working_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
