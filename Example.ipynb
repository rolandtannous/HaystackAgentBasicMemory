{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03324c18-6197-4f8a-b783-55833f9c7a7e",
   "metadata": {},
   "source": [
    "This is notebook example showcases the usage of Basic Memory for Haystack Agents. \n",
    "The tools and agents use text-embedding-ada-002 and davinci-3 models from OpenAI.\n",
    "The notebook is compatible with jupyter notebooks and google colabs.\n",
    "\n",
    "\n",
    "- Assumes you have installed and are running an elastic documentstore service on your local system or server\n",
    "- If using google colab then uncomment the below 4 cells to install elastic search and launch the ES server.\n",
    "\n",
    "For guides on how to install:\n",
    "- ElasticSearch on Ubuntu: https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-20-04\n",
    "- The Elastic Search official docker image:https://hub.docker.com/_/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d5390-64a5-4d51-b1fb-4a0b2e0d66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# uncomment everything below this line if you're using colab\n",
    "\n",
    "# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.7.0-linux-x86_64.tar.gz\n",
    "# tar -xzf elasticsearch-8.7.0-linux-x86_64.tar.gz\n",
    "# chown -R daemon:daemon elasticsearch-8.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7e307-cc00-446c-b316-ada7eda2aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash --bg\n",
    "# uncomment everything below this line if you're using colab\n",
    "#elasticsearch-8.7.0/bin/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3d828-8830-4f68-8ba5-305611dfabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment everything below this line if you're using colab\n",
    "# from haystack.utils import launch_es\n",
    "# launch_es()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ea29762d-b971-4bf6-b7d7-632ac9d932d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.local/lib/python3.10/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "35faee3b-efc6-4087-a606-3a33ea7cf3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activate logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "465e00cf-1236-4510-90aa-f4b7dd4b65ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required haystack libraries\n",
    "import os\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.pipelines import GenerativeQAPipeline\n",
    "from haystack.nodes import OpenAIAnswerGenerator\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.nodes.base import BaseComponent\n",
    "from haystack.agents import Agent, Tool\n",
    "from HaystackAgentBasicMemory.MemoryRecallNode import MemoryRecallNode\n",
    "from HaystackAgentBasicMemory.Agentchat import chat\n",
    "from haystack.pipelines import Pipeline\n",
    "from datasets import load_dataset\n",
    "from haystack.nodes import PromptTemplate, PromptNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "07fde7df-8ae1-4ae7-9bcc-bf4d65cb0635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set your openAI API key\n",
    "openai_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "84a4e13c-917d-4b9c-a158-f916e179293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple list variable to hold our memory\n",
    "memory_database = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "044e81e8-fee1-42d0-9cf1-1a1bcbd0dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roland/.local/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "/home/roland/haystack/haystack/document_stores/search_engine.py:169: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  return self.client.indices.exists(index_name, headers=headers)\n",
      "/home/roland/haystack/haystack/document_stores/elasticsearch.py:499: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  indices = self.client.indices.get(index_name, headers=headers)\n"
     ]
    }
   ],
   "source": [
    "# Get the host where Elasticsearch is running, defaults to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "\n",
    "# define ElasticSearchDocumentStore. Embeddings dimension set to be compatible with text-embedding-ada-002 \n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"document-small-test\",\n",
    "    search_fields = [\"title\", \"text\"],\n",
    "    embedding_field=\"embedding\", \n",
    "    excluded_meta_data=[\"embedding\"],\n",
    "    embedding_dim=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "43a0bbde-1e9e-4913-a7b8-8a066fa12670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - datasets.builder -  Found cached dataset parquet (/home/roland/.cache/huggingface/datasets/bilgeyucel___parquet/bilgeyucel--seven-wonders-6536ac0e9c84233f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "# load seven wonders dataset from datasets and write documents into elasticsearch document store\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "document_store.write_documents(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3ce039fc-e7ac-4d55-8036-4f3288848d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0 - Number of GPUs: 1\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model text-embedding-ada-002\n",
      "Updating embeddings:   0%|          | 0/151 [00:00<?, ? Docs/s]\n",
      "Calculating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[AWARNING - haystack.nodes.retriever._openai_encoder -  The prompt has been truncated from 702 tokens to 512 tokens to fit within the max token limit. Reduce the length of the prompt to prevent it from being cut off.\n",
      "\n",
      "Calculating embeddings:  20%|██        | 1/5 [00:00<00:02,  1.94it/s]\u001b[A\n",
      "Calculating embeddings:  40%|████      | 2/5 [00:01<00:01,  2.01it/s]\u001b[A\n",
      "Calculating embeddings:  60%|██████    | 3/5 [00:01<00:01,  1.96it/s]\u001b[A\n",
      "Calculating embeddings:  80%|████████  | 4/5 [00:02<00:00,  1.90it/s]\u001b[AWARNING - haystack.nodes.retriever._openai_encoder -  The prompt has been truncated from 579 tokens to 512 tokens to fit within the max token limit. Reduce the length of the prompt to prevent it from being cut off.\n",
      "\n",
      "Calculating embeddings: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\u001b[A\n",
      "Updating embeddings: 10000 Docs [00:03, 2842.80 Docs/s]        \n"
     ]
    }
   ],
   "source": [
    "# define retriever model , update dense vector embeddings on document store index and define generator model\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"text-embedding-ada-002\",\n",
    "    api_key=openai_api_key,\n",
    "    top_k=3,\n",
    ")\n",
    "document_store.update_embeddings(retriever=retriever)\n",
    "generator = OpenAIAnswerGenerator(api_key=openai_api_key,\n",
    "                                  model=\"text-davinci-003\",\n",
    "                                  temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "35a1c528-0d07-4ff0-beaf-74653c3fa9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the openai search engine \n",
    "open_ai_search_engine = GenerativeQAPipeline(retriever=retriever, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "680b5652-8749-4571-b02f-7965ad6d68a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the generative QA pipeline\n",
    "pipe = Pipeline()\n",
    "pipe.add_node(component=open_ai_search_engine.get_node(\"Retriever\"), name=\"Retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=open_ai_search_engine.get_node(\"Generator\"), name=\"Generator\", inputs=[\"Retriever\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e9bc0205-2aa8-4e81-be71-2d9b1f9cc7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declare and create the Memory tool using the MemoryRecallNode tool\n",
    "memory_node = MemoryRecallNode(memory_database)\n",
    "memory_tool = Tool(name=\"Memory\",\n",
    "                   pipeline_or_node=memory_node,\n",
    "                   description=\"Your memory. Always access this tool first to remember what you have learned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3a4d37f6-a260-4479-b6f4-9d23cb6e4b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#custom agent prompt\n",
    "agent_prompt = PromptTemplate(\n",
    "    name=\"memory-shot-react\",\n",
    "    prompt_text=\"You are a helpful and knowledgeable agent. To achieve your goal of answering complex questions \"\n",
    "                \"correctly, you have access to the following tools:\\n\\n\"\n",
    "                \"{tool_names_with_descriptions}\\n\\n\"\n",
    "                \"To answer questions, you'll need to go through multiple steps involving step-by-step thinking and \"\n",
    "                \"selecting the appropriate tools and give them the question as input; tools will respond with observations.\\n\"\n",
    "                \"Decide if the observations provided by the tool contains information needed to answer questions.\\n\"\n",
    "                \"When you are ready for a final answer, respond with the Final Answer:\\n\\n\"\n",
    "                \"You should avoid knowledge that is present in your internal knowledge. You do not use prior knowledge, only the observations provided by the tools available to you\"\n",
    "                \"Use the following format:\\n\\n\"\n",
    "                \"Question: the question to be answered\\n\"\n",
    "                \"Thought: Reason if you have the final answer. If yes, answer the question. If not, find out the missing information needed to answer it.\\n\"\n",
    "                \"Tool: pick one of {tool_names}. Always access the Memory tool first \\n\"\n",
    "                \"Tool Input: the full updated question to be answered\\n\"\n",
    "                \"Observation: the tool will respond with the observation\\n\"\n",
    "                \"...\\n\"\n",
    "                \"Final Answer: the final answer to the question\\n\\n\"\n",
    "                \"Thought, Tool, Tool Input, and Observation steps can be repeated multiple times, but sometimes we can find an answer in the first pass\\n\"\n",
    "                \"---\\n\\n\"\n",
    "                \"Question: {query}\\n\"\n",
    "                \"Thought: Let's think step-by-step, I first need to \",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "92b759a0-28f1-459c-a57b-792ada06794d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create agent prompt node and define our Agent \"memory_agent\"\n",
    "prompt_node = PromptNode(model_name_or_path=\"text-davinci-003\", api_key=openai_api_key, max_length=512, stop_words=[\"Observation:\"])\n",
    "memory_agent = Agent(prompt_node=prompt_node, prompt_template=agent_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7912be9d-6ab4-499e-b420-1a650ee07090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define our search tool based on the GEnerative QA pipeline declared earlier\n",
    "search_tool = Tool(name=\"DocumentStore_QA\",\n",
    "                   pipeline_or_node=pipe,\n",
    "                   description=\"Access this tool to find out missing information needed to answer questions\",\n",
    "                   output_variable=\"answers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1e0e0c9d-256c-4bb2-8763-10f3048d72cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the memory and the search tools to the agent\n",
    "memory_agent.add_tool(search_tool)\n",
    "memory_agent.add_tool(memory_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ca98fdf3-13be-462a-a3b7-ce95672d9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent memory-shot-react started with {'query': 'What does the Rhodes Statue look like?', 'params': None}\n",
      "\u001b[32m access\u001b[0m\u001b[32m my\u001b[0m\u001b[32m Memory\u001b[0m\u001b[32m tool\u001b[0m\u001b[32m to\u001b[0m\u001b[32m remember\u001b[0m\u001b[32m what\u001b[0m\u001b[32m I\u001b[0m\u001b[32m know\u001b[0m\u001b[32m about\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Rhodes\u001b[0m\u001b[32m Statue\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Memory\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m What\u001b[0m\u001b[32m do\u001b[0m\u001b[32m I\u001b[0m\u001b[32m know\u001b[0m\u001b[32m about\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Rhodes\u001b[0m\u001b[32m Statue\u001b[0m\u001b[32m?\u001b[0m\u001b[32m\n",
      "\u001b[0mObservation: \u001b[33m[]\u001b[0m\n",
      "Thought: \u001b[32m I\u001b[0m\u001b[32m'm\u001b[0m\u001b[32m not\u001b[0m\u001b[32m sure\u001b[0m\u001b[32m,\u001b[0m\u001b[32m let\u001b[0m\u001b[32m's\u001b[0m\u001b[32m look\u001b[0m\u001b[32m for\u001b[0m\u001b[32m more\u001b[0m\u001b[32m information\u001b[0m\u001b[32m and\u001b[0m\u001b[32m access\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Document\u001b[0m\u001b[32mStore\u001b[0m\u001b[32m_\u001b[0m\u001b[32mQ\u001b[0m\u001b[32mA\u001b[0m\u001b[32m tool\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Document\u001b[0m\u001b[32mStore\u001b[0m\u001b[32m_\u001b[0m\u001b[32mQ\u001b[0m\u001b[32mA\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m What\u001b[0m\u001b[32m does\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Rhodes\u001b[0m\u001b[32m Statue\u001b[0m\u001b[32m look\u001b[0m\u001b[32m like\u001b[0m\u001b[32m?\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "/home/roland/haystack/haystack/document_stores/elasticsearch.py:376: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  result = self.client.search(index=index, body=body, request_timeout=300, headers=headers)[\"hits\"][\"hits\"]\n",
      "WARNING - haystack.utils.openai_utils -  5 out of the 5 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m Scholars do not know what the statue looked like, but they have a good idea of what the head and face looked like. It is thought to have had curly hair with evenly spaced spikes of bronze or silver flame radiating, similar to the images found\u001b[0m\n",
      "Thought: \u001b[32m I\u001b[0m\u001b[32m have\u001b[0m\u001b[32m enough\u001b[0m\u001b[32m information\u001b[0m\u001b[32m to\u001b[0m\u001b[32m answer\u001b[0m\u001b[32m the\u001b[0m\u001b[32m question\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Scholars\u001b[0m\u001b[32m have\u001b[0m\u001b[32m a\u001b[0m\u001b[32m good\u001b[0m\u001b[32m idea\u001b[0m\u001b[32m of\u001b[0m\u001b[32m what\u001b[0m\u001b[32m the\u001b[0m\u001b[32m head\u001b[0m\u001b[32m and\u001b[0m\u001b[32m face\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Rhodes\u001b[0m\u001b[32m Statue\u001b[0m\u001b[32m looked\u001b[0m\u001b[32m like\u001b[0m\u001b[32m -\u001b[0m\u001b[32m it\u001b[0m\u001b[32m is\u001b[0m\u001b[32m thought\u001b[0m\u001b[32m to\u001b[0m\u001b[32m have\u001b[0m\u001b[32m had\u001b[0m\u001b[32m curly\u001b[0m\u001b[32m hair\u001b[0m\u001b[32m with\u001b[0m\u001b[32m evenly\u001b[0m\u001b[32m spaced\u001b[0m\u001b[32m spikes\u001b[0m\u001b[32m of\u001b[0m\u001b[32m bronze\u001b[0m\u001b[32m or\u001b[0m\u001b[32m silver\u001b[0m\u001b[32m flame\u001b[0m\u001b[32m radi\u001b[0m\u001b[32mating\u001b[0m\u001b[32m,\u001b[0m\u001b[32m similar\u001b[0m\u001b[32m to\u001b[0m\u001b[32m the\u001b[0m\u001b[32m images\u001b[0m\u001b[32m found\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Initial question\n",
    "# chat(\"What does the Rhodes Statue look like?\", memory_agent, memory_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bf74a1fa-1cb0-420e-8e9b-5aa80f9739b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "chat with me (or 'quit' to exit):  who destroyed the rhodes statue?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent memory-shot-react started with {'query': 'who destroyed the rhodes statue?', 'params': None}\n",
      "\u001b[32m consult\u001b[0m\u001b[32m my\u001b[0m\u001b[32m memory\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Memory\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Who\u001b[0m\u001b[32m destroyed\u001b[0m\u001b[32m the\u001b[0m\u001b[32m r\u001b[0m\u001b[32mhod\u001b[0m\u001b[32mes\u001b[0m\u001b[32m statue\u001b[0m\u001b[32m?\u001b[0m\u001b[32m\n",
      "\u001b[0mObservation: \u001b[33m[]\u001b[0m\n",
      "Thought: \u001b[32m I\u001b[0m\u001b[32m don\u001b[0m\u001b[32m't\u001b[0m\u001b[32m have\u001b[0m\u001b[32m the\u001b[0m\u001b[32m information\u001b[0m\u001b[32m I\u001b[0m\u001b[32m need\u001b[0m\u001b[32m in\u001b[0m\u001b[32m my\u001b[0m\u001b[32m memory\u001b[0m\u001b[32m,\u001b[0m\u001b[32m let\u001b[0m\u001b[32m's\u001b[0m\u001b[32m access\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Document\u001b[0m\u001b[32mStore\u001b[0m\u001b[32m_\u001b[0m\u001b[32mQ\u001b[0m\u001b[32mA\u001b[0m\u001b[32m tool\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Document\u001b[0m\u001b[32mStore\u001b[0m\u001b[32m_\u001b[0m\u001b[32mQ\u001b[0m\u001b[32mA\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Who\u001b[0m\u001b[32m destroyed\u001b[0m\u001b[32m the\u001b[0m\u001b[32m r\u001b[0m\u001b[32mhod\u001b[0m\u001b[32mes\u001b[0m\u001b[32m statue\u001b[0m\u001b[32m?\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
      "/home/roland/haystack/haystack/document_stores/elasticsearch.py:376: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  result = self.client.search(index=index, body=body, request_timeout=300, headers=headers)[\"hits\"][\"hits\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m The ultimate fate of the remains of the statue is uncertain. It is believed that it was destroyed by an Arab force under Muslim general Muawiyah I in 653 AD.\u001b[0m\n",
      "Thought: \u001b[32m That\u001b[0m\u001b[32m's\u001b[0m\u001b[32m the\u001b[0m\u001b[32m answer\u001b[0m\u001b[32m,\u001b[0m\u001b[32m let\u001b[0m\u001b[32m's\u001b[0m\u001b[32m provide\u001b[0m\u001b[32m the\u001b[0m\u001b[32m final\u001b[0m\u001b[32m answer\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m The\u001b[0m\u001b[32m r\u001b[0m\u001b[32mhod\u001b[0m\u001b[32mes\u001b[0m\u001b[32m statue\u001b[0m\u001b[32m was\u001b[0m\u001b[32m destroyed\u001b[0m\u001b[32m by\u001b[0m\u001b[32m an\u001b[0m\u001b[32m Arab\u001b[0m\u001b[32m force\u001b[0m\u001b[32m under\u001b[0m\u001b[32m Muslim\u001b[0m\u001b[32m general\u001b[0m\u001b[32m Mu\u001b[0m\u001b[32maw\u001b[0m\u001b[32miyah\u001b[0m\u001b[32m I\u001b[0m\u001b[32m in\u001b[0m\u001b[32m 6\u001b[0m\u001b[32m53\u001b[0m\u001b[32m AD\u001b[0m\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "chat with me (or 'quit' to exit):  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"\\nchat with me (or 'quit' to exit): \")\n",
    "\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        # call the chat wrapper function defined from the HaystackAgentBasicMemory library\n",
    "        chat(user_input, memory_agent, memory_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2b802-0947-4d73-b2ea-723bc1accbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-final",
   "language": "python",
   "name": "haystack-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
